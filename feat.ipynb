{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script is an implementation of a **Feature-Based Change Detector** using **VGG19** as a feature extractor. Below is a **detailed breakdown** of every part of the script, including functions, parameters, key concepts, and execution flow.  \n",
    "\n",
    "---\n",
    "\n",
    "# **Overview**  \n",
    "This script:  \n",
    "- Uses **VGG19**, a pre-trained deep learning model, to extract intermediate-level features from images.  \n",
    "- Computes the **feature difference** between two images to detect changes.  \n",
    "- Uses **Otsuâ€™s thresholding method** to segment the change map.  \n",
    "- Displays a **binary change map**, where changed regions appear in white, and unchanged regions appear in black.\n",
    "\n",
    "---\n",
    "\n",
    "# **Key Components of the Code**\n",
    "### **1. Importing Libraries**\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from skimage import filters\n",
    "from skimage import exposure\n",
    "from keras import backend as K\n",
    "```\n",
    "- `tensorflow` and `keras` â†’ Used for deep learning operations.  \n",
    "- `VGG19` â†’ A deep CNN model pre-trained on ImageNet, used as a **feature extractor**.  \n",
    "- `image` and `preprocess_input` â†’ Used for image preprocessing.  \n",
    "- `numpy` â†’ Used for numerical operations.  \n",
    "- `matplotlib.pyplot` â†’ Used for visualization (plotting images).  \n",
    "- `sys` â†’ Used for handling command-line arguments.  \n",
    "- `filters` â†’ Used for **Otsuâ€™s thresholding** to determine a segmentation threshold.  \n",
    "- `exposure` â†’ Used for histogram calculations.  \n",
    "- `K` â†’ Provides access to the **backend** (TensorFlow/Keras) for low-level tensor manipulations.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Function: `get_activations`**\n",
    "This function extracts **intermediate layer outputs (features)** from a given model.\n",
    "\n",
    "```python\n",
    "def get_activations(model, layer_idx, X_batch):\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer_idx].output,])\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations\n",
    "```\n",
    "### **Parameters**\n",
    "- `model` â†’ The pre-trained **VGG19 model**.  \n",
    "- `layer_idx` â†’ Index of the layer from which features will be extracted.  \n",
    "- `X_batch` â†’ The input image (in a batch format).  \n",
    "\n",
    "### **Working**\n",
    "- Creates a **Keras function** that takes an image as input and returns the output of the specified **CNN layer**.  \n",
    "- `K.function([...])` defines a function to retrieve **layer outputs**.  \n",
    "- `K.learning_phase()` is set to `0` to indicate that this is an **inference phase** (not training).  \n",
    "- `activations` stores the extracted **feature maps** of the given image.  \n",
    "- Finally, the function returns the extracted **feature maps**.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Function: `extra_feat` (Feature Extraction)**\n",
    "This function extracts **features from multiple layers** of VGG19.\n",
    "\n",
    "```python\n",
    "def extra_feat(img_path):\n",
    "    base_model = VGG19(weights='imagenet', include_top=False)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    block1_pool_features = get_activations(base_model, 3, x)\n",
    "    block2_pool_features = get_activations(base_model, 6, x)\n",
    "    block3_pool_features = get_activations(base_model, 10, x)\n",
    "    block4_pool_features = get_activations(base_model, 14, x)\n",
    "    block5_pool_features = get_activations(base_model, 18, x)\n",
    "\n",
    "    x1 = tf.image.resize_images(block1_pool_features[0], [112, 112])\n",
    "    x2 = tf.image.resize_images(block2_pool_features[0], [112, 112])\n",
    "    x3 = tf.image.resize_images(block3_pool_features[0], [112, 112])\n",
    "    x4 = tf.image.resize_images(block4_pool_features[0], [112, 112])\n",
    "    x5 = tf.image.resize_images(block5_pool_features[0], [112, 112])\n",
    "\n",
    "    F = tf.concat([x3, x2, x1, x4, x5], 3)\n",
    "    return F\n",
    "```\n",
    "### **Parameters**\n",
    "- `img_path` â†’ Path of the input image.\n",
    "\n",
    "### **Working**\n",
    "1. **Loads the VGG19 model** with pre-trained ImageNet weights.  \n",
    "2. **Loads the input image**, resizes it to `224x224`.  \n",
    "3. Converts image to **numpy array**, expands dimensions, and applies **preprocessing**.  \n",
    "4. Extracts **features from different layers** of the VGG19 model:  \n",
    "   - `block1_pool_features` â†’ Low-level features.  \n",
    "   - `block5_pool_features` â†’ High-level features.  \n",
    "5. **Resizes the feature maps** to `112x112` for consistency.  \n",
    "6. **Concatenates** features from different blocks.  \n",
    "7. Returns the **final feature representation** (`F`).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Function: `main()`**\n",
    "Handles the **execution flow** of the program.\n",
    "\n",
    "```python\n",
    "def main():\n",
    "  if (len(sys.argv)) > 3:\n",
    "    print(\"Invalid number of input arguments\")\n",
    "    exit(0)\n",
    "\n",
    "  img_path1 = sys.argv[1]\n",
    "  img_path2 = sys.argv[2]\n",
    "\n",
    "  sess = tf.InteractiveSession()\n",
    "\n",
    "  F1 = extra_feat(img_path1)\n",
    "  F1 = tf.square(F1)\n",
    "  F2 = extra_feat(img_path2)\n",
    "  F2 = tf.square(F2)\n",
    "  d = tf.subtract(F1, F2)\n",
    "  d = tf.square(d)\n",
    "  d = tf.reduce_sum(d, axis=3)\n",
    "\n",
    "  dis = (d.eval())\n",
    "  dis = np.resize(dis, [112, 112])\n",
    "\n",
    "  val = filters.threshold_otsu(dis[:, :])\n",
    "  hist, bins_center = exposure.histogram(dis[:, :], nbins=256)\n",
    "\n",
    "  plt.title('Unstructured change')\n",
    "  plt.imshow(dis[:, :] < val, cmap='gray', interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "```\n",
    "\n",
    "### **Execution Flow**\n",
    "1. **Reads Command-Line Arguments**  \n",
    "   - Takes two image paths from command line.  \n",
    "2. **Extracts Features for Both Images**  \n",
    "   - Uses `extra_feat()` to extract **VGG19-based features** for both images.  \n",
    "3. **Computes Change Map**  \n",
    "   - Squares the extracted features.  \n",
    "   - Computes pixel-wise **difference** between the two feature maps.  \n",
    "   - Squares the difference and **sums along the depth axis** to get a **2D change map**.  \n",
    "4. **Applies Otsuâ€™s Thresholding**  \n",
    "   - Determines a threshold value to **segment the change regions**.  \n",
    "5. **Displays Binary Change Map**  \n",
    "   - Uses `plt.imshow()` to visualize **change regions** in grayscale.  \n",
    "\n",
    "---\n",
    "\n",
    "## **5. Running the Script**\n",
    "To execute:\n",
    "```sh\n",
    "python script.py image1.jpg image2.jpg\n",
    "```\n",
    "**Example**:\n",
    "```sh\n",
    "python change_detector.py img1.jpg img2.jpg\n",
    "```\n",
    "- **Output**:  \n",
    "  - A **binary image** showing **changed regions**.\n",
    "\n",
    "---\n",
    "\n",
    "# **Key Concepts Explained**\n",
    "### **1. VGG19 Architecture**\n",
    "- A **deep convolutional neural network** (CNN).  \n",
    "- Uses **5 convolutional blocks** followed by **fully connected layers**.  \n",
    "- Extracts **low-to-high level features** for effective **feature comparison**.  \n",
    "\n",
    "### **2. Feature Extraction**\n",
    "- Uses **VGG19 layers** to get feature representations.  \n",
    "- Low-level features â†’ **Edges, textures**.  \n",
    "- High-level features â†’ **Object structures**.  \n",
    "\n",
    "### **3. Otsuâ€™s Thresholding**\n",
    "- Determines an **optimal threshold** for image segmentation.  \n",
    "- **Automatically selects** the threshold without manual tuning.  \n",
    "\n",
    "---\n",
    "\n",
    "# **Conclusion**\n",
    "This script efficiently detects **changes** between two images using **VGG19** features and **Otsuâ€™s thresholding**. It can be used in **remote sensing, medical imaging, and object detection**. ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
